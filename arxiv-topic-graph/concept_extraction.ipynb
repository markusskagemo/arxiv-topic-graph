{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import preprocessing\n",
    "\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time series forecasting is a crucial component of many important applications, ranging from forecasting the stock markets to energy load prediction. The high-dimensionality, velocity and variety of th'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#texts = preprocessing.corpus_tokens()\n",
    "#dictionary = corpora.Dictionary(texts)\n",
    "flat_metadata = preprocessing.flat_unique()\n",
    "summaries = [paper['summary'].replace('\\n', ' ') for paper in flat_metadata]\n",
    "\n",
    "# Sample\n",
    "summaries[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.examples import sentences\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9232/9232 [07:04<00:00, 25.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "corpus_orgs = []\n",
    "for i in tqdm(range(len(summaries))):\n",
    "    doc = nlp(summaries[i])\n",
    "    doc_orgs = []\n",
    "    for entity in doc.ents:\n",
    "        #print(entity.text, entity.label_)\n",
    "        if entity.label_ == 'ORG':\n",
    "            text = entity.text\n",
    "            #print(text)\n",
    "            doc_orgs.append(text)\n",
    "    corpus_orgs.append(doc_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pylab import draw_networkx, draw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gograph():\n",
    "    G = nx.Graph()\n",
    "    #G.add_edge('A', 'B', weight=4)\n",
    "    #nx.shortest_path(G, 'A', 'B', weight='weight')\n",
    "    sim = []\n",
    "    N = 50\n",
    "    #for i in range(1, len(summaries)):\n",
    "    for i in tqdm(range(1, N)):\n",
    "        for j in range(1, N):\n",
    "            # Determine semantic similarities\n",
    "            doc1 = nlp(summaries[i])\n",
    "            doc2 = nlp(summaries[j])\n",
    "            similarity = doc1.similarity(doc2)\n",
    "\n",
    "            G.add_edge(str(j), str(i), weight=1-similarity)\n",
    "\n",
    "    try:\n",
    "        draw_networkx(G)\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        plt.draw()\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.xlim(0.87, 1)\n",
    "    sns.distplot(sim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.681674599647522),\n",
       " ('cats', 0.6815836429595947),\n",
       " ('pet', 0.5870364904403687),\n",
       " ('dogs', 0.540766716003418),\n",
       " ('feline', 0.48979708552360535),\n",
       " ('monkey', 0.48794347047805786),\n",
       " ('horse', 0.4732131063938141),\n",
       " ('pets', 0.46348586678504944),\n",
       " ('rabbit', 0.4608757197856903),\n",
       " ('leopard', 0.4585462808609009)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\"glove-wiki-gigaword-300\")  # download the model and return as object ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'monte carlo' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f26a18034a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"monte carlo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'monte carlo' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Temporal Logistic Neural', 'BoF'],\n",
       " ['Gaussian'],\n",
       " ['Monte Carlo', 'Monte Carlo', 'PDMP', 'Monte Carlo'],\n",
       " ['LSMC', 'LSMC'],\n",
       " ['Monte Carlo'],\n",
       " ['VaR', 'VaR', 'MH', 'Monte Carlo', 'MH', 'Monte Carlo', 'MH'],\n",
       " [],\n",
       " ['FRTB', 'FRTB'],\n",
       " ['SAAD', 'AAD'],\n",
       " [],\n",
       " ['\\\\mathcal{X',\n",
       "  'SIAM/',\n",
       "  'ASA Journal on Uncertainty Quantification',\n",
       "  '  ',\n",
       "  'UNet',\n",
       "  'SegNet',\n",
       "  'DeconvNet'],\n",
       " ['Laplace'],\n",
       " ['PML', 'PMG', 'PML', 'PMG', 'PML'],\n",
       " ['MPDATA', 'MPDATA', 'MPDATA', 'MPDATA'],\n",
       " ['CN2017', 'the Expanded Local Variance Gamma'],\n",
       " [],\n",
       " ['Hagan'],\n",
       " [],\n",
       " ['Monte Carlo', 'MC', 'Monte Carlo'],\n",
       " ['Neural Network', 'Experience Replay', 'DQN']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_orgs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
